{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e729962e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.listdir()\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9934637e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"medical_students_dataset.csv\")\n",
    "##https://www.kaggle.com/datasets/slmsshk/medical-students-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a53735f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df.index = [i for i in range(len(df.index))]\n",
    "df = df.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe083432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Blood Type</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Heart Rate</th>\n",
       "      <th>Blood Pressure</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Smoking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>182.537664</td>\n",
       "      <td>55.741083</td>\n",
       "      <td>A</td>\n",
       "      <td>16.729017</td>\n",
       "      <td>98.260293</td>\n",
       "      <td>76.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>186.489402</td>\n",
       "      <td>52.389752</td>\n",
       "      <td>AB</td>\n",
       "      <td>15.063921</td>\n",
       "      <td>98.227788</td>\n",
       "      <td>85.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>182.416302</td>\n",
       "      <td>76.371050</td>\n",
       "      <td>AB</td>\n",
       "      <td>22.950992</td>\n",
       "      <td>98.118274</td>\n",
       "      <td>86.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>166.489929</td>\n",
       "      <td>49.955569</td>\n",
       "      <td>B</td>\n",
       "      <td>18.022207</td>\n",
       "      <td>98.809750</td>\n",
       "      <td>82.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>179.909041</td>\n",
       "      <td>90.679436</td>\n",
       "      <td>AB</td>\n",
       "      <td>28.015787</td>\n",
       "      <td>98.782269</td>\n",
       "      <td>81.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50788</th>\n",
       "      <td>25.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>156.297842</td>\n",
       "      <td>90.690186</td>\n",
       "      <td>B</td>\n",
       "      <td>37.123963</td>\n",
       "      <td>98.664591</td>\n",
       "      <td>70.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50789</th>\n",
       "      <td>23.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>162.884951</td>\n",
       "      <td>82.485778</td>\n",
       "      <td>B</td>\n",
       "      <td>31.089745</td>\n",
       "      <td>98.852347</td>\n",
       "      <td>65.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50790</th>\n",
       "      <td>34.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>165.651315</td>\n",
       "      <td>93.099756</td>\n",
       "      <td>A</td>\n",
       "      <td>33.928040</td>\n",
       "      <td>97.862209</td>\n",
       "      <td>62.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50791</th>\n",
       "      <td>34.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>161.590030</td>\n",
       "      <td>90.877589</td>\n",
       "      <td>B</td>\n",
       "      <td>34.803881</td>\n",
       "      <td>98.728836</td>\n",
       "      <td>70.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50792</th>\n",
       "      <td>30.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>156.446944</td>\n",
       "      <td>50.142824</td>\n",
       "      <td>A</td>\n",
       "      <td>20.486823</td>\n",
       "      <td>98.994212</td>\n",
       "      <td>61.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50793 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  Gender      Height     Weight Blood Type        BMI  Temperature  \\\n",
       "0      32.0  Female  182.537664  55.741083          A  16.729017    98.260293   \n",
       "1      28.0    Male  186.489402  52.389752         AB  15.063921    98.227788   \n",
       "2      34.0  Female  182.416302  76.371050         AB  22.950992    98.118274   \n",
       "3      31.0    Male  166.489929  49.955569          B  18.022207    98.809750   \n",
       "4      29.0  Female  179.909041  90.679436         AB  28.015787    98.782269   \n",
       "...     ...     ...         ...        ...        ...        ...          ...   \n",
       "50788  25.0  Female  156.297842  90.690186          B  37.123963    98.664591   \n",
       "50789  23.0  Female  162.884951  82.485778          B  31.089745    98.852347   \n",
       "50790  34.0    Male  165.651315  93.099756          A  33.928040    97.862209   \n",
       "50791  34.0    Male  161.590030  90.877589          B  34.803881    98.728836   \n",
       "50792  30.0  Female  156.446944  50.142824          A  20.486823    98.994212   \n",
       "\n",
       "       Heart Rate  Blood Pressure  Cholesterol Diabetes Smoking  \n",
       "0            76.0           130.0        216.0      Yes      No  \n",
       "1            85.0           123.0        128.0       No      No  \n",
       "2            86.0            97.0        247.0       No      No  \n",
       "3            82.0            96.0        223.0       No      No  \n",
       "4            81.0           108.0        227.0       No     Yes  \n",
       "...           ...             ...          ...      ...     ...  \n",
       "50788        70.0           132.0        164.0      Yes      No  \n",
       "50789        65.0            94.0        188.0       No     Yes  \n",
       "50790        62.0           100.0        205.0       No      No  \n",
       "50791        70.0            96.0        208.0       No      No  \n",
       "50792        61.0           106.0        225.0       No      No  \n",
       "\n",
       "[50793 rows x 12 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df ##  some preprocessing here!!!!  to fit the things into "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "443b6d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "non_numeric = [\"Gender\", \"Blood Type\", \"Diabetes\", \"Smoking\"]\n",
    "numeric = {\"Age\":0, \"Height\":0, \"Weight\":0, \"BMI\":0, \"Temperature\":0, \"Heart Rate\":0, \"Blood Pressure\":0, \"Cholesterol\":0}\n",
    "one_hotted = [\"Blood Type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93b234aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in non_numeric:\n",
    "    df[feature]= LabelEncoder().fit_transform(df[feature])\n",
    "\n",
    "for feature in numeric.keys():\n",
    "    mean = df[feature].mean()\n",
    "    std = df[feature].std()\n",
    "    numeric[feature] = mean, std\n",
    "    df[feature] = (df[feature] - mean)/(std + 1e-5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98fb3d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"Blood Type\", axis = 1)\n",
    "#df_onehotted = OneHotEncoder(sparse_output=False).fit_transform(np.array(df[\"Blood Type\"]).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba2f0afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f212fdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_splitted(df:pd.DataFrame)->tuple[np.ndarray,]:\n",
    "    df = df.sample(frac = 1)\n",
    "    N = int(len(df)*0.8)\n",
    "    train, test = map(np.array, [df.iloc[:N,:], df.iloc[N:, :]])\n",
    "    return train, test\n",
    "train, test = return_splitted(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "799a5adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import auto_encoder\n",
    "from auto_encoder import auto_encoder_bb\n",
    "from typing import Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db3d0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124044af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#auto_encoder_bb([20, 50, 4])(torch.randn(10, 20), encoder_output = True)\n",
    "F.one_hot(torch.tensor([0, 3, 1]), 5).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f01e6ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(numerical_columns:list[int] = [], \n",
    "         binary_columns:list[int] = [],\n",
    "         categorical_columns:list[tuple[float,float]] = [],\n",
    "         )->Callable[[torch.Tensor, torch.Tensor],torch.Tensor]:\n",
    "        #@torch.compile ## since we have a lot of for loops compiling may save some time!!!\n",
    "        def temp_loss(X:torch.Tensor, y:torch.Tensor)->torch.Tensor:\n",
    "            loss = nn.MSELoss()(X[:, numerical_columns], y[:, numerical_columns])\n",
    "            for feature in categorical_columns:\n",
    "                i, class_size = feature\n",
    "                loss += F.cross_entropy(X[:, i:i+class_size], y[:, i:i+class_size])\n",
    "            for i in binary_columns:\n",
    "                loss += F.binary_cross_entropy_with_logits(X[:, i], y[:, i])               \n",
    "            return loss\n",
    "        return temp_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21323948",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = loss(numerical_columns = [0,2,3,4,5,6,7,8], binary_columns = [1,9,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29918489",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_df = torch.tensor(df.to_numpy(), dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5573595",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = auto_encoder_bb([11, 10, 9, 8, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e5a874f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eeb4bb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is now 3.071112632751465\n",
      "The loss is now 2.8233225345611572\n",
      "The loss is now 2.4975943565368652\n",
      "The loss is now 2.404484748840332\n",
      "The loss is now 2.372570514678955\n",
      "The loss is now 2.3289947509765625\n",
      "The loss is now 2.3010337352752686\n",
      "The loss is now 2.2798378467559814\n",
      "The loss is now 2.267202138900757\n",
      "The loss is now 2.260279417037964\n",
      "The loss is now 2.2562623023986816\n",
      "The loss is now 2.2529959678649902\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10000\u001b[39m):\n\u001b[0;32m      3\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m----> 4\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model(torch_df)\n\u001b[0;32m      5\u001b[0m     loss_ \u001b[38;5;241m=\u001b[39m loss_fn(y_pred, torch_df)\n\u001b[0;32m      6\u001b[0m     loss_\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\torch2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Desktop\\git_repos\\GAN_implementations\\Fair_Gan\\auto_encoder.py:63\u001b[0m, in \u001b[0;36mauto_encoder_bb.forward\u001b[1;34m(self, x, encoder_output)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_output:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m enc_output\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__decoder__(enc_output)\n",
      "File \u001b[1;32m~\\Desktop\\git_repos\\GAN_implementations\\Fair_Gan\\auto_encoder.py:53\u001b[0m, in \u001b[0;36mauto_encoder_bb.__decoder__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     51\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mlinear(x, weight\u001b[38;5;241m.\u001b[39mT, bias)\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepth \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 53\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(x)            \n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\torch2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\torch2\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:685\u001b[0m, in \u001b[0;36mGELU.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    684\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 685\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mgelu(\u001b[38;5;28minput\u001b[39m, approximate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapproximate)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = Adam(model.parameters())\n",
    "for i in range(10000):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(torch_df)\n",
    "    loss_ = loss_fn(y_pred, torch_df)\n",
    "    loss_.backward()\n",
    "    optimizer.step()\n",
    "    if i % 100 == 0:\n",
    "        print(f\"The loss is now {loss_.item()}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55af825",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(torch_df[6, :], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1217b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_df[3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7fe32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(torch_df[3, :])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
